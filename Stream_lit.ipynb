{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VinhRP/Makeup_Detection_Yolov8/blob/main/Stream_lit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1NGO2u47IMD",
        "outputId": "f77e706f-1bd7-4e5f-b26d-140552bdff70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sdt2v1QKEov4",
        "outputId": "f468257e-26af-4d8e-d9c1-566f99d15a65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cttSe3p1pydW"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahkdifp8pymT",
        "outputId": "3c61bdb5-c7db-44dc-b830-ac479da2f24b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.220 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 27.0/166.8 GB disk)\n"
          ]
        }
      ],
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQVFGe95q9zZ",
        "outputId": "4aa1891c-fd0a-4426-a304-9cb57d76bdc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from torchvision.models._api import WeightsEnum\n",
        "from torch.hub import load_state_dict_from_url\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from typing import List, Tuple\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "from ultralytics import YOLO\n",
        "\n",
        "def get_state_dict(self, *args, **kwargs):\n",
        "    kwargs.pop(\"check_hash\")\n",
        "    return load_state_dict_from_url(self.url, *args, **kwargs)\n",
        "WeightsEnum.get_state_dict = get_state_dict\n",
        "\n",
        "res50 = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
        "res50 = resnet50(weights=\"DEFAULT\")\n",
        "\n",
        "for module, param in zip(res50.modules(), res50.parameters()):\n",
        "\tif isinstance(module, torch.nn.BatchNorm2d):\n",
        "\t\tparam.requires_grad = False\n",
        "\n",
        "# define the network head and attach it to the model\n",
        "numFeatures = res50.fc.in_features\n",
        "\n",
        "headModel = torch.nn.Sequential(\n",
        "\ttorch.nn.Linear(numFeatures, 512),\n",
        "\ttorch.nn.ReLU(),\n",
        "\ttorch.nn.Dropout(0.25),\n",
        "\ttorch.nn.Linear(512, 256),\n",
        "\ttorch.nn.ReLU(),\n",
        "\ttorch.nn.Dropout(0.5),\n",
        "\ttorch.nn.Linear(256, 2)\n",
        ")\n",
        "res50.fc = headModel\n",
        "\n",
        "res50.load_state_dict(torch.load(\"/content/drive/MyDrive/Test.pth\"))\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "image_size: Tuple[int, int] = (224, 224)\n",
        "class_names = ['Make_up', 'Non_Make_up']\n",
        "\n",
        "image_transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize(image_size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(\n",
        "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "res50.to(device)\n",
        "res50.eval()\n",
        "\n",
        "image_file = st.file_uploader(\"Upload an image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "if image_file is not None:\n",
        "  our_image = Image.open(image_file).convert(\"RGB\")\n",
        "  yolo = YOLO('/content/drive/MyDrive/face_detection_224.pt')\n",
        "  results = yolo.predict(our_image) # predict on an image\n",
        "  for r in results:\n",
        "    cords = r.boxes.xyxy[0].tolist()\n",
        "    cords = [round(x) for x in cords]\n",
        "    img = Image.fromarray(r.plot()[..., :: -1]) ## Original image\n",
        "    img2 = img.crop(cords) ##Croped image\n",
        "  with torch.inference_mode():\n",
        "    transformed_image = image_transform(img2).unsqueeze(dim=0)\n",
        "    target_image_pred = res50(transformed_image.to(device))\n",
        "    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n",
        "    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)\n",
        "  information = f\"Pred: {class_names[target_image_pred_label]} | Prob: {target_image_pred_probs.max():.3f}\"\n",
        "  st.text(information)\n",
        "  st.image(our_image, channels=\"RGB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sVNmXqb7Ruc",
        "outputId": "3fda7ae5-81a7-41fb-b98a-ba4d4fc82d77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors and audited 22 packages in 1.625s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 1 \u001b[93mmoderate\u001b[0m severity vulnerability\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OzHHCFL7WzX",
        "outputId": "bf6d1a50-8453-48d7-cb71-9fdcdda7c607"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.91.111.237\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 1.904s\n",
            "your url is: https://sad-poets-bow.loca.lt\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNW1VQddBQZ/3vmi9MrkUYJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}